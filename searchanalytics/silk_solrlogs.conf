input {
	file {
		type => "solrlog"

		path => [ "/Users/ravikrishnamurthy/Documents/demos/slk-4.7.0/solr-4.7.0/SiLK/logs/*" ]
		#path => [ "/Users/ravikrishnamurthy/Documents/demos/slk-4.7.0/solrWriterForLogStash/logstash_deploy/test.log" ]
		exclude => ["*.gz","*.zip","*.tgz"]
		sincedb_path => "/dev/null"
    	start_position => "beginning"
   }
}
filter {
	if [type] == "solrlog" {
	
		
		grok {
			match => ["message", "INFO %{DATA} %{TIMESTAMP_ISO8601:received_at}; %{DATA}; \[%{DATA:collection}\] webapp=%{DATA:webapp} path=%{DATA:searchhandler} params={%{DATA}q=%{DATA:queryterms}[&}]%{DATA} hits=%{BASE10NUM:hits} status=%{BASE10NUM:status} QTime=%{BASE10NUM:qtime}"]
		}

		if ("_grokparsefailure" in [tags]) {
      		drop{}
    	}
	
	
		date {
		# Try to pull the time stamp from the 'received_at' field (parsed above with grok)
			match => [ "received_at", "yyyy-MM-dd HH:mm:ss.SSS" ]
		}	
	
	}
}	


output {
	stdout { debug => true codec => "rubydebug"}
	#lucidworks_solr_lsv133 { collection_host => "localhost" collection_port => "8888" collection_name => "solrlogs" field_prefix => "event_" force_commit => false flush_size => 1000 idle_flush_time => 1 }
}
